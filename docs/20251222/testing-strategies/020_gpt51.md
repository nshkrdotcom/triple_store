## What “confidence” should mean for this stack

For TripleStore, confidence is less about “did we hit the happy path” and more about proving a small set of *invariants* across three fault domains:

1. **Elixir semantics** (dictionary, index selection, streams, manager serialization)
2. **NIF safety + contract** (no UB, no VM crashes, correct error shapes, correct lifetime behavior)
3. **RocksDB durability + isolation** (snapshots, batches, reopen, crash recovery)

A sound strategy is to make those invariants explicit, then test them at three layers with increasing realism and cost.

---

## 1) Codify the contracts and invariants (this drives every test)

### NIF contract (must be written down and regression-tested)

For each NIF entrypoint, define:

* accepted argument types
* return shapes (including error atoms/tuples)
* lifecycle rules (what remains valid after `close/1`, `iterator_close/1`, `release_snapshot/1`)
* concurrency expectations (thread-safe, can run concurrently, what races are permitted)

Given your Rust implementation now uses `RwLock<Option<Arc<SharedDb>>>` and iterators/snapshots hold their own `Arc<SharedDb>`, the most important explicit contract is:

* After `NIF.close(db)`, **new operations on `db` must return `{:error, :already_closed}`**, but **existing iterators/snapshots must remain safe and functional** until closed/GC’d.

That is the single highest-risk area historically (use-after-free), and it deserves dedicated “this would have crashed the VM” regression tests.

### Storage invariants (DB-level correctness)

* Column families exist and are the expected set.
* `write_batch` / `mixed_batch` are atomic w.r.t. visible state.
* Snapshot reads are point-in-time consistent.
* Prefix iterators never leak keys outside the prefix boundary.
* `iterator_seek` does not break prefix bounds.

### Higher-level invariants (Elixir logic)

* Dictionary is a bijection for dictionary-allocated IDs: `str2id` ↔ `id2str`.
* Inline-encoded IDs decode without DB access and never collide with dictionary-allocated space.
* Index consistency: inserting one triple produces exactly 3 keys (SPO/POS/OSP) and lookup enumerates the same triples as a reference model.
* Manager serialization: concurrent `get_or_create_id` for the same term must return the same ID.

---

## 2) A practical test pyramid that targets the risk

### Layer A — Fast unit/property tests (run on every commit)

**Goal:** prove invariants cheaply; catch logic bugs early.

* **Elixir unit tests** for `Dictionary`, `Index`, `Adapter` with a reference model.

  * Use a pure Elixir “oracle” (e.g., `MapSet` of triples + map of term↔id) to compare results.
* **Property-based tests** (recommended): generate random terms/triples and check invariants hold across many sequences of operations.

  * Add `{:stream_data, "~> 0.6", only: :test}` and run:

    * dictionary round-trips
    * index insert/delete idempotence
    * lookup equivalence against the oracle

These tests are excellent at finding subtle boundary issues (empty prefixes, large binaries, ordering, etc.) without needing huge fixtures.

### Layer B — NIF contract tests (ExUnit calling the real NIF; run on every commit)

**Goal:** prove the Rustler boundary does what Elixir expects and remains safe under concurrency.

Create a dedicated suite (example naming):

* `test/triple_store/backend/rocksdb/nif_contract_test.exs`
* `test/triple_store/backend/rocksdb/nif_lifetime_test.exs`
* `test/triple_store/backend/rocksdb/nif_concurrency_test.exs`

Key cases to cover (deterministic):

* Open/close idempotence and `is_open/1`
* `get_path/1` and errors after close
* Invalid CF behavior (`{:error, {:invalid_cf, cf}}` shape)
* Batch atomicity at the API level (invalid operation/CF should not mutate DB)
* Iterator semantics:

  * empty prefix scans all
  * prefix boundary stops correctly
  * `iterator_close` and subsequent calls return `{:error, :iterator_closed}`
  * `iterator_seek` works and still respects prefix
* Snapshot semantics:

  * snapshot sees old value after write
  * released snapshot errors
  * snapshot iterator boundary

**Most important regression test:** iterator/snapshot safety across `close/1`.

Example (in-process) regression test for the lifetime contract:

```elixir
test "iterator remains safe and usable after db close" do
  {:ok, db} = NIF.open(tmp_path())
  :ok = NIF.put(db, :spo, "s1p1o1", "")
  :ok = NIF.put(db, :spo, "s1p1o2", "")

  {:ok, iter} = NIF.prefix_iterator(db, :spo, "s1")
  assert :ok = NIF.close(db)

  # db handle is closed for new ops
  assert {:error, :already_closed} = NIF.get(db, :spo, "s1p1o1")

  # iterator must still be safe and yield
  assert {:ok, "s1p1o1", ""} = NIF.iterator_next(iter)
  assert {:ok, "s1p1o2", ""} = NIF.iterator_next(iter)
  assert :iterator_end = NIF.iterator_next(iter)
  assert :ok = NIF.iterator_close(iter)
end
```

Do the same for snapshots:

* create snapshot
* close db
* snapshot_get still returns consistent values
* release_snapshot works

### Layer C — “Crash harness” tests (run in CI, but isolated in an OS process)

**Goal:** catch VM-crashing bugs (UB, segfaults) without taking down the test runner.

If a NIF segfaults, it can kill the BEAM. Those tests must run in a subprocess.

Pattern:

* ExUnit test spawns `elixir -e '...'` or `mix run -e '...'`
* Asserts exit status is 0 and output matches expectations

Example harness test:

```elixir
test "close while iterator alive does not crash BEAM (subprocess)" do
  script = """
  alias TripleStore.Backend.RocksDB.NIF
  path = System.tmp_dir!() <> "/ts_" <> Integer.to_string(System.unique_integer([:positive]))
  {:ok, db} = NIF.open(path)
  :ok = NIF.put(db, :spo, "s1p1o1", "")
  {:ok, iter} = NIF.prefix_iterator(db, :spo, "s1")
  :ok = NIF.close(db)
  IO.inspect(NIF.iterator_next(iter), label: "next")
  """

  {out, status} = System.cmd("elixir", ["-e", script], stderr_to_stdout: true)
  assert status == 0
  assert out =~ "next"
end
```

This is the right place to put “formerly unsafe” sequences and concurrency races that could crash the VM.

---

## 3) Rust-side testing: make the NIF crate itself accountable

Even though the “truth” is the BEAM-facing contract, you still want Rust tests for:

* iterator prefix boundary logic
* batch parsing/validation
* lifetime semantics around `Arc<SharedDb>` (to the extent possible)

Practical approach:

* Add Rust unit tests in `native/rocksdb_nif/tests/` using `tempfile` for isolated DB dirs.
* Factor internal helpers into testable functions where you can (e.g., CF mapping, prefix checks).
* Run `cargo test` in CI separately from `mix test`.

Two high-leverage additions for Rust confidence:

1. **Sanitizer builds (nightly/CI job)**

   * Build the NIF with AddressSanitizer/UBSan and run the crash harness suite.
   * This is the most direct way to detect use-after-free, double-free, etc.
   * Treat sanitizer failures as blocking.

2. **Fuzzing (nightly)**

   * Use `cargo fuzz` to hammer:

     * batch operation decoding (invalid tuples, weird binaries)
     * iterator seek/bounds sequences
   * Fuzzing is extremely effective at shaking out “should never happen” input paths.

---

## 4) DB-level durability and recovery tests (system/integration tier)

These are slower, but they’re what make you confident in “the DB itself”:

### Persistence correctness

* Write across CFs → `close` → reopen → verify reads.
* Especially important for dictionary + index: you want “restart does not break invariants”.

### Crash recovery (subprocess + kill)

* Spawn a subprocess that:

  * opens DB
  * performs a mix of puts/batches
  * optionally creates snapshots/iterators
* Kill it hard (SIGKILL) mid-run.
* Reopen in parent process and assert:

  * DB opens cleanly (no corruption)
  * invariants hold (at minimum: no partial index state that violates your own rules)

If you want stronger assertions (e.g., “this batch must be present”), you’ll need either:

* synchronous writes for those test operations, or
* an explicit “fsync/flush” operation exposed by the NIF for test mode.

### Concurrency soak

A tagged test (excluded by default) that runs for ~10–60 seconds:

* many processes doing get/put/delete/batch
* occasional snapshot reads
* occasional iterator scans
* occasional close+reopen on fresh DB paths

This is where deadlocks, starvation, and subtle races show up.

---

## 5) End-to-end semantic correctness (once SPARQL + OWL are fully present)

For the full triple store (not just RocksDB):

* **SPARQL 1.1 compliance:** run the W3C SPARQL 1.1 test suite (or a curated subset in CI, full suite nightly).
* **OWL 2 RL reasoning:** run known OWL 2 RL entailment test cases; validate materialization results.
* **Differential testing:** compare query results against a reference engine on the same dataset for a curated corpus (small/medium datasets).

This becomes your “semantic oracle” that catches optimizer and reasoner correctness issues.

---

## 6) CI structure that keeps velocity while increasing confidence

A workable gating scheme:

### Per PR (fast, deterministic)

* `mix format --check-formatted`
* `mix compile --warnings-as-errors`
* `mix test` (unit + NIF contract tests)
* `cargo test` for the NIF crate
* `mix dialyzer` (if you can keep it stable)

### Merge to main (slower)

* property tests with higher iteration counts
* crash harness suite (subprocess)
* concurrency tests (bounded)

### Nightly/weekly (deep safety)

* sanitizer build + crash harness
* fuzzing for N hours
* long soak test
* durability/crash-recovery scenarios

---

## 7) The “next 5 things” I would implement in this repo

1. **NIF lifetime regression tests** (iterator/snapshot across `close/1`), including a subprocess harness version.
2. **Batch atomicity regression tests**: invalid op/CF must not mutate state.
3. **Property tests** for index consistency vs a pure Elixir oracle.
4. **Crash-recovery harness**: kill mid-write, reopen, verify invariants.
5. **Sanitizer CI job**: ASAN/UBSan build of the NIF + run harness tests.

If you do only these five, you will substantially increase confidence specifically in the Rustler/NIF boundary and the DB semantics, while keeping the day-to-day suite fast.
